---
title: "Neural Network Basics: From Logistic Regression To Backpropagation"
layout: post
math: true
date: 2018-12-31
categories: DeepLearning
permalink: deeplearning/Neural-Network-Basic/
---

본 포스트에서는 신경망의 기초를 다룬다. 먼저 Logistic Regression을 다룰 것이고, 이를 학습하기 위한 Gradient Descent 방법을 소개할 것이다. 그리고 이를 확장하여 Multi-layer Neural Network의 parameter를 tuning하기 위한 Backpropagation 알고리즘을 소개할 것이다.

## 구성

- Logistic Regression
    - [Logistic Regression 이론: AND Gate 예제]({{site.baseurl}}/deeplearning/Logistic-Regression/)
    - [Logistic Regression 실전: And Gate 만들어보기 (Python)]({{site.baseurl}}/deeplearning/and_gate_with_logistic_regression/)
- Multi-Layer Neural Network
    - [Multi-Layer Neural Network의 이론: XOR Gate 예제]({{site.baseurl}}/deeplearning/Multi-Layer-Neural-Network/)
    - [Multi-Layer Neural Network의 이론: XOR Gate 만들어보기 (Python)]({{site.baseurl}}/deeplearning/xor-gate-multilayer-neural-network/)
